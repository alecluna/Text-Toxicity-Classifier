### Authors

Ryan Morris, Josh Singh, Alec Luna

## Motivation

In this competition, we're challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. We are using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias. We are to develop strategies to reduce unintended bias in machine learning models, and help the Conversation AI team, and the entire industry, build models that work well for a wide range of conversations.

Kaggle competition here:

https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification
