{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(value):\n",
    "    if value>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a list to a tuple\n",
    "def totuple(a):\n",
    "    try:\n",
    "        return tuple(totuple(i) for i in a)\n",
    "    except TypeError:\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(cleaned_data, data_size):\n",
    "    if(cleaned_data == \"1\"): # get cleaned and preprosessed data\n",
    "        return pd.read_csv('train_preprocessed.csv',nrows=data_size) \n",
    "    else:\n",
    "        return pd.read_csv('train.csv',nrows=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(dct):\n",
    "    print(\"Parameters:\")\n",
    "    for item, amount in dct.items():\n",
    "        print(\"{} ({})\".format(item, amount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(train_df, max_words, max_len):  \n",
    "    train_df =  train_df[['id','target','comment_text']]\n",
    "    train_df['truth'] = train_df['target'].apply(target)\n",
    "    train_df['comment_text'] = preprocess(train_df['comment_text'])\n",
    "    \n",
    "    X = train_df.comment_text\n",
    "    Y = train_df.truth\n",
    "    le = LabelEncoder()\n",
    "    Y = le.fit_transform(Y)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    \n",
    "    tok = Tokenizer(num_words=max_words)\n",
    "    tok.fit_on_texts(X_train)\n",
    "    sequences = tok.texts_to_sequences(X_train)\n",
    "    sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "    \n",
    "    return (sequences_matrix, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BATCH_SIZE, LSTM_UNITS, MAX_LEN, MAX_WORDS, DROPOUT, BIDIRECTIONAL, DOUBLE_LSTM_LAYER\n",
    "\n",
    "def build_rnn(max_len , max_words, lstm_units, dropout, bidirectional, double_ltsm):\n",
    "#     calculate Params\n",
    "    DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "\n",
    "#     build RNN\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    \n",
    "    if(double_ltsm):\n",
    "        if(bidirectional):   \n",
    "            layer = Bidirectional(LSTM(lstm_units, return_sequences=True))(layer)\n",
    "        else:\n",
    "            layer = LSTM(lstm_units, return_sequences=True)(layer)\n",
    "        \n",
    "    if(bidirectional):   \n",
    "        layer = Bidirectional(LSTM(lstm_units))(layer)\n",
    "    else:\n",
    "        layer = LSTM(lstm_units)(layer)\n",
    "        \n",
    "    \n",
    "    layer = Dense(DENSE_HIDDEN_UNITS, name='Dense')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    \n",
    "    if(dropout):\n",
    "        layer = Dropout(0.3)(layer)\n",
    "    \n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  grid search - every combination will be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "CLEANED_DATA ([True, False])\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE ([512])\n",
      "LSTM_UNITS ([128])\n",
      "EPOCHS ([4])\n",
      "MAX_LEN ([150])\n",
      "MAX_WORDS ([2000])\n",
      "DROPOUT ([True])\n",
      "BIDIRECTIONAL ([True, False])\n",
      "DOUBLE_LSTM_LAYER ([True, False])\n"
     ]
    }
   ],
   "source": [
    "# feature sellection variables\n",
    "CLEANED_DATA = [True,\n",
    "                False\n",
    "               ]\n",
    "DATA_ROWS = 200000\n",
    "\n",
    "# Parameter tuning variablesmax_words = [2000] #\n",
    "BATCH_SIZE = [512] # How many comments are used for each training cycle \n",
    "LSTM_UNITS = [\n",
    "#     64, \n",
    "    128\n",
    "    ] # how many units are in the LSTM\n",
    "\n",
    "EPOCHS = [4] # num of times to go over entire training data set\n",
    "MAX_LEN = [150] # numder of words allowed before the comment is cut off\n",
    "MAX_WORDS = [2000] # number of features (if word isn't found, it's skipped)\n",
    "DROPOUT = [\n",
    "    True, \n",
    "#     False\n",
    "] # dropout layer ratio 0 for so drop out\n",
    "\n",
    "BIDIRECTIONAL = [\n",
    "    True, \n",
    "    False\n",
    "] # Whether or not to use the bidirectional STML layers\n",
    "DOUBLE_LSTM_LAYER = [\n",
    "    True, \n",
    "    False\n",
    "] # Whether or not to use the bidirectional STML layers\n",
    "\n",
    "help_display = dict(zip(\n",
    "    ['CLEANED_DATA','DATA_ROWS','BATCH_SIZE', 'LSTM_UNITS','EPOCHS', 'MAX_LEN', 'MAX_WORDS','DROPOUT', 'BIDIRECTIONAL', 'DOUBLE_LSTM_LAYER'],\n",
    "    [CLEANED_DATA,DATA_ROWS,BATCH_SIZE, LSTM_UNITS,EPOCHS, MAX_LEN, MAX_WORDS,DROPOUT, BIDIRECTIONAL, DOUBLE_LSTM_LAYER]\n",
    "))\n",
    "\n",
    "\n",
    "parameter_grid = np.array(np.meshgrid(CLEANED_DATA,\n",
    "                                      DATA_ROWS,\n",
    "                                      BATCH_SIZE, \n",
    "                                      LSTM_UNITS,\n",
    "                                      EPOCHS, \n",
    "                                      MAX_LEN, \n",
    "                                      MAX_WORDS,\n",
    "                                      DROPOUT, \n",
    "                                      BIDIRECTIONAL, \n",
    "                                      DOUBLE_LSTM_LAYER\n",
    "                                     )).T.reshape(-1,10)\n",
    "\n",
    "# print('bat, unit, epoc, len, words, drop, bid, 2-layers')\n",
    "print_parameters(help_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\avnee\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Users\\avnee\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Users\\avnee\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\Users\\avnee\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 809,633\n",
      "Trainable params: 809,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From E:\\Users\\avnee\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 874s 7ms/step - loss: 0.2317 - acc: 0.9297 - val_loss: 0.2066 - val_acc: 0.9346\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 821s 6ms/step - loss: 0.2068 - acc: 0.9345 - val_loss: 0.2130 - val_acc: 0.9346\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 150, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 809,633\n",
      "Trainable params: 809,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 827s 6ms/step - loss: 0.2318 - acc: 0.9294 - val_loss: 0.2051 - val_acc: 0.9358\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 824s 6ms/step - loss: 0.2047 - acc: 0.9354 - val_loss: 0.2266 - val_acc: 0.9361\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 150, 128)          91648     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 389,793\n",
      "Trainable params: 389,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 487s 4ms/step - loss: 0.2327 - acc: 0.9295 - val_loss: 0.2344 - val_acc: 0.9285\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 485s 4ms/step - loss: 0.2059 - acc: 0.9354 - val_loss: 0.1991 - val_acc: 0.9362\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 485s 4ms/step - loss: 0.1996 - acc: 0.9363 - val_loss: 0.1978 - val_acc: 0.9374\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 485s 4ms/step - loss: 0.1952 - acc: 0.9365 - val_loss: 0.2002 - val_acc: 0.9375\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 150, 128)          91648     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 389,793\n",
      "Trainable params: 389,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 488s 4ms/step - loss: 0.2321 - acc: 0.9293 - val_loss: 0.2068 - val_acc: 0.9341\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 486s 4ms/step - loss: 0.2045 - acc: 0.9357 - val_loss: 0.1974 - val_acc: 0.9369\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 485s 4ms/step - loss: 0.1990 - acc: 0.9364 - val_loss: 0.2042 - val_acc: 0.9327\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 415,393\n",
      "Trainable params: 415,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 427s 3ms/step - loss: 0.2483 - acc: 0.9281 - val_loss: 0.2080 - val_acc: 0.9365\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.2042 - acc: 0.9358 - val_loss: 0.1996 - val_acc: 0.9374\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.1987 - acc: 0.9357 - val_loss: 0.1936 - val_acc: 0.9386\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 425s 3ms/step - loss: 0.1911 - acc: 0.9378 - val_loss: 0.1919 - val_acc: 0.9392\n",
      "Epoch 5/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.1892 - acc: 0.9381 - val_loss: 0.1941 - val_acc: 0.9393\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 415,393\n",
      "Trainable params: 415,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 430s 3ms/step - loss: 0.2781 - acc: 0.9242 - val_loss: 0.2431 - val_acc: 0.9285\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.2126 - acc: 0.9329 - val_loss: 0.2010 - val_acc: 0.9363\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.1987 - acc: 0.9359 - val_loss: 0.1970 - val_acc: 0.9375\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 426s 3ms/step - loss: 0.1951 - acc: 0.9364 - val_loss: 0.1983 - val_acc: 0.9377\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 258,209\n",
      "Trainable params: 258,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 247s 2ms/step - loss: 0.2388 - acc: 0.9277 - val_loss: 0.2093 - val_acc: 0.9315\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 245s 2ms/step - loss: 0.2041 - acc: 0.9352 - val_loss: 0.2046 - val_acc: 0.9321\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 247s 2ms/step - loss: 0.1957 - acc: 0.9369 - val_loss: 0.1995 - val_acc: 0.9344\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 246s 2ms/step - loss: 0.1921 - acc: 0.9369 - val_loss: 0.2010 - val_acc: 0.9341\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 258,209\n",
      "Trainable params: 258,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 247s 2ms/step - loss: 0.2390 - acc: 0.9278 - val_loss: 0.2112 - val_acc: 0.9349\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 245s 2ms/step - loss: 0.2085 - acc: 0.9338 - val_loss: 0.1968 - val_acc: 0.9375\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 245s 2ms/step - loss: 0.2010 - acc: 0.9352 - val_loss: 0.1999 - val_acc: 0.9382\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 150, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 809,633\n",
      "Trainable params: 809,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 841s 7ms/step - loss: 0.2318 - acc: 0.9296 - val_loss: 0.2299 - val_acc: 0.9347\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 830s 6ms/step - loss: 0.2089 - acc: 0.9354 - val_loss: 0.1966 - val_acc: 0.9372\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 830s 6ms/step - loss: 0.1994 - acc: 0.9367 - val_loss: 0.1938 - val_acc: 0.9386\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 829s 6ms/step - loss: 0.1931 - acc: 0.9374 - val_loss: 0.1906 - val_acc: 0.9388\n",
      "Epoch 5/5\n",
      "128000/128000 [==============================] - 832s 7ms/step - loss: 0.1905 - acc: 0.9386 - val_loss: 0.1898 - val_acc: 0.9393\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 150, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 809,633\n",
      "Trainable params: 809,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 853s 7ms/step - loss: 0.2315 - acc: 0.9299 - val_loss: 0.2010 - val_acc: 0.9365\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 832s 6ms/step - loss: 0.2006 - acc: 0.9368 - val_loss: 0.1951 - val_acc: 0.9372\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 836s 7ms/step - loss: 0.1952 - acc: 0.9372 - val_loss: 0.1979 - val_acc: 0.9365\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 150, 128)          91648     \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 389,793\n",
      "Trainable params: 389,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 489s 4ms/step - loss: 0.2287 - acc: 0.9308 - val_loss: 0.2375 - val_acc: 0.9301\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 488s 4ms/step - loss: 0.2032 - acc: 0.9363 - val_loss: 0.2032 - val_acc: 0.9379\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 485s 4ms/step - loss: 0.1980 - acc: 0.9368 - val_loss: 0.1977 - val_acc: 0.9374\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 486s 4ms/step - loss: 0.1940 - acc: 0.9375 - val_loss: 0.1976 - val_acc: 0.9383\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 150, 128)          91648     \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 389,793\n",
      "Trainable params: 389,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 491s 4ms/step - loss: 0.2339 - acc: 0.9298 - val_loss: 0.2120 - val_acc: 0.9335\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 489s 4ms/step - loss: 0.2083 - acc: 0.9341 - val_loss: 0.2072 - val_acc: 0.9338\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 488s 4ms/step - loss: 0.2010 - acc: 0.9353 - val_loss: 0.2011 - val_acc: 0.9353\n",
      "Epoch 4/5\n",
      "128000/128000 [==============================] - 487s 4ms/step - loss: 0.1956 - acc: 0.9368 - val_loss: 0.2011 - val_acc: 0.9351\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 415,393\n",
      "Trainable params: 415,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 432s 3ms/step - loss: 0.2357 - acc: 0.9283 - val_loss: 0.2012 - val_acc: 0.9367\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 428s 3ms/step - loss: 0.2030 - acc: 0.9358 - val_loss: 0.1972 - val_acc: 0.9365\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 428s 3ms/step - loss: 0.1938 - acc: 0.9377 - val_loss: 0.1977 - val_acc: 0.9374\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (1)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 415,393\n",
      "Trainable params: 415,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 425s 3ms/step - loss: 0.2352 - acc: 0.9280 - val_loss: 0.2073 - val_acc: 0.9365\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 421s 3ms/step - loss: 0.2075 - acc: 0.9336 - val_loss: 0.1934 - val_acc: 0.9386\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 421s 3ms/step - loss: 0.1999 - acc: 0.9351 - val_loss: 0.1994 - val_acc: 0.9378\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (1)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 258,209\n",
      "Trainable params: 258,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 252s 2ms/step - loss: 0.2333 - acc: 0.9286 - val_loss: 0.2047 - val_acc: 0.9357\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 247s 2ms/step - loss: 0.2053 - acc: 0.9341 - val_loss: 0.1986 - val_acc: 0.9373\n",
      "Epoch 3/5\n",
      "128000/128000 [==============================] - 246s 2ms/step - loss: 0.1960 - acc: 0.9370 - val_loss: 0.2095 - val_acc: 0.9347\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "Parameters:\n",
      "CLEANED_DATA (0)\n",
      "DATA_ROWS (200000)\n",
      "BATCH_SIZE (512)\n",
      "LSTM_UNITS (128)\n",
      "EPOCHS (4)\n",
      "MAX_LEN (150)\n",
      "MAX_WORDS (2000)\n",
      "DROPOUT (1)\n",
      "BIDIRECTIONAL (0)\n",
      "DOUBLE_LSTM_LAYER (0)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_16 (Embedding)     (None, 150, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 258,209\n",
      "Trainable params: 258,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "128000/128000 [==============================] - 252s 2ms/step - loss: 0.2504 - acc: 0.9270 - val_loss: 0.2166 - val_acc: 0.9310\n",
      "Epoch 2/5\n",
      "128000/128000 [==============================] - 248s 2ms/step - loss: 0.2126 - acc: 0.9336 - val_loss: 0.2210 - val_acc: 0.9354\n"
     ]
    }
   ],
   "source": [
    "for use_cleaned_data in CLEANED_DATA:\n",
    "    train_df = getData(use_cleaned_data, DATA_ROWS)\n",
    "\n",
    "    for row in parameter_grid:\n",
    "\n",
    "        (CLEANED_DATA,DATA_ROWS,BATCH_SIZE, \n",
    "        LSTM_UNITS,EPOCHS, MAX_LEN, MAX_WORDS,\n",
    "        DROPOUT, BIDIRECTIONAL, DOUBLE_LSTM_LAYER) = totuple(row)\n",
    "\n",
    "        #Print display for tracking parameters\n",
    "        help_display = dict(zip(\n",
    "            ['CLEANED_DATA','DATA_ROWS','BATCH_SIZE', 'LSTM_UNITS','EPOCHS', 'MAX_LEN', 'MAX_WORDS','DROPOUT', 'BIDIRECTIONAL', 'DOUBLE_LSTM_LAYER'],\n",
    "            [CLEANED_DATA,DATA_ROWS,BATCH_SIZE, LSTM_UNITS,EPOCHS, MAX_LEN, MAX_WORDS,DROPOUT, BIDIRECTIONAL, DOUBLE_LSTM_LAYER]\n",
    "        ))\n",
    "        print_parameters(help_display)\n",
    "        sequences_matrix, Y_train = prepareData(train_df, MAX_WORDS, MAX_LEN) # get sequence matrix\n",
    "    #     max_len , max_words, lstm_units, dropout, bidirectional, double_ltsm\n",
    "        model = build_rnn(MAX_LEN, MAX_WORDS, LSTM_UNITS, DROPOUT, BIDIRECTIONAL, DOUBLE_LSTM_LAYER)\n",
    "\n",
    "        print_parameters(help_display)\n",
    "        print (model.summary())\n",
    "        model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "        model.fit(sequences_matrix,Y_train,batch_size=128,epochs=5,\n",
    "                  validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.001)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "              validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
